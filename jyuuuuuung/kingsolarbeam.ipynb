{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_data = pd.read_csv('train.csv',encoding='utf-8')\n",
    "solar_data.drop(['Day', 'Hour','Minute'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(solar_data, index, input_days=7, output_days=2):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0,48*7):\n",
    "        dataX += list(np.array(solar_data.loc[index+i].tolist()))\n",
    "    for i in range(48*7,48*(7+2)):\n",
    "        dataY += solar_data.loc[[0+i],['TARGET']].values.tolist()\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "input_data, output_data = [], []\n",
    "last_index = 3*365*48-48*(7+2)\n",
    "index_list = list(range(0,last_index+1,48))\n",
    "for i in index_list:\n",
    "    X, Y = create_dataset(solar_data,i)\n",
    "    input_data.append(X)\n",
    "    output_data.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분배\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(input_data), np.array(output_data), test_size = 0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=2016,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "for i in range(2):\n",
    "    model.add(Dense(32,activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습과정 설정\n",
    "model.compile(loss='mean_squared_error', optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3956.7756 - val_loss: 362.1172\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1233.5121 - val_loss: 361.1643\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 879.8285 - val_loss: 383.7140\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 661.0286 - val_loss: 355.6917\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 537.3306 - val_loss: 350.7098\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 523.9133 - val_loss: 346.6278\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 460.4540 - val_loss: 344.1017\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 429.0879 - val_loss: 343.4328\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 422.7383 - val_loss: 341.2451\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 409.1224 - val_loss: 338.8871\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 397.5267 - val_loss: 336.3052\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 384.4677 - val_loss: 334.0782\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 379.6756 - val_loss: 335.5307\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 389.8044 - val_loss: 334.8459\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 374.7919 - val_loss: 333.9897\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 374.1581 - val_loss: 333.6494\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 366.0538 - val_loss: 332.2704\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 364.1980 - val_loss: 332.8223\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 368.1151 - val_loss: 334.2574\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 369.0499 - val_loss: 334.6102\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 355.8617 - val_loss: 333.0201\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 358.5381 - val_loss: 332.6014\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 350.2849 - val_loss: 331.6910\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 354.2678 - val_loss: 331.4283\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 359.7810 - val_loss: 332.2942\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 354.2191 - val_loss: 332.7665\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 346.3056 - val_loss: 332.0681\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 344.7349 - val_loss: 331.8513\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 347.8337 - val_loss: 331.9279\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 348.1297 - val_loss: 332.1220\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 352.0251 - val_loss: 331.9931\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 351.8134 - val_loss: 332.4130\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 348.4587 - val_loss: 333.2791\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 347.2922 - val_loss: 333.3048\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 345.7628 - val_loss: 333.3353\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 346.2556 - val_loss: 333.7996\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 341.8964 - val_loss: 333.1777\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 345.1078 - val_loss: 332.7267\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 346.9414 - val_loss: 332.9106\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 346.7500 - val_loss: 333.1732\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 346.3940 - val_loss: 333.8269\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 350.9011 - val_loss: 334.2857\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 349.7767 - val_loss: 334.5984\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 345.2310 - val_loss: 334.4536\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.6743 - val_loss: 334.0362\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.6990 - val_loss: 333.3605\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 341.7995 - val_loss: 332.7998\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.4959 - val_loss: 332.6070\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 344.8334 - val_loss: 332.9711\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 340.1852 - val_loss: 332.7673\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 341.6322 - val_loss: 332.5679\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 340.9169 - val_loss: 332.3195\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 345.2913 - val_loss: 332.5765\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 340.4725 - val_loss: 332.1226\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 339.3064 - val_loss: 331.8822\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.7085 - val_loss: 331.6835\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.0292 - val_loss: 332.5040\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.7073 - val_loss: 332.9265\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 341.5115 - val_loss: 332.6077\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.6240 - val_loss: 332.1324\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.1992 - val_loss: 331.7014\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 343.1479 - val_loss: 332.1326\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 341.1704 - val_loss: 331.9298\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 340.1408 - val_loss: 331.6826\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.9602 - val_loss: 331.5279\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.9625 - val_loss: 331.4906\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 339.7532 - val_loss: 331.7448\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 338.0653 - val_loss: 331.3009\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 338.2337 - val_loss: 331.4911\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.6814 - val_loss: 331.2670\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 342.6599 - val_loss: 331.2840\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 339.7950 - val_loss: 331.7882\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 340.0335 - val_loss: 331.7041\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.6740 - val_loss: 331.3528\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 338.6339 - val_loss: 330.7959\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.7090 - val_loss: 330.9034\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.1416 - val_loss: 330.7871\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 339.2289 - val_loss: 331.2296\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.3954 - val_loss: 331.2660\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 340.0123 - val_loss: 331.3874\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 339.0614 - val_loss: 331.4192\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.6111 - val_loss: 331.2851\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.8691 - val_loss: 330.9977\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.8461 - val_loss: 330.8524\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.2915 - val_loss: 330.6284\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.9312 - val_loss: 329.4687\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.8629 - val_loss: 329.1410\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.2951 - val_loss: 329.0526\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.1303 - val_loss: 328.5439\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.6503 - val_loss: 329.1265\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.3288 - val_loss: 329.3647\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.7354 - val_loss: 329.2642\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.5821 - val_loss: 328.8570\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.8181 - val_loss: 328.9877\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.0592 - val_loss: 328.2063\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 337.5432 - val_loss: 328.8761\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.1324 - val_loss: 328.6660\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.0370 - val_loss: 328.5256\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.2702 - val_loss: 328.8214\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.3359 - val_loss: 328.9418\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.9427 - val_loss: 329.1213\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.6497 - val_loss: 328.9392\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.6375 - val_loss: 329.0733\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.8403 - val_loss: 329.6571\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.9892 - val_loss: 329.5302\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.0146 - val_loss: 329.1376\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.8551 - val_loss: 328.6701\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.4771 - val_loss: 328.7250\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.7309 - val_loss: 328.6974\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.9198 - val_loss: 329.2551\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.9738 - val_loss: 328.7513\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.3763 - val_loss: 328.9845\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.2454 - val_loss: 328.2432\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.0521 - val_loss: 327.9507\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.6183 - val_loss: 328.5907\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 335.2849 - val_loss: 328.5862\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.0889 - val_loss: 328.4773\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.9119 - val_loss: 328.8400\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.8594 - val_loss: 328.4638\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.4965 - val_loss: 329.2216\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 334.5199 - val_loss: 328.8309\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.5932 - val_loss: 328.7204\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.0092 - val_loss: 328.3256\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.6851 - val_loss: 328.2293\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.8192 - val_loss: 327.7239\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.5060 - val_loss: 327.4995\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.9945 - val_loss: 326.7075\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.7062 - val_loss: 326.9041\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.6529 - val_loss: 327.2309\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.9727 - val_loss: 326.7377\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.6107 - val_loss: 326.1501\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.0257 - val_loss: 325.9750\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.6591 - val_loss: 325.8399\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.7911 - val_loss: 325.2528\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.8842 - val_loss: 325.3003\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 328.1540 - val_loss: 324.3763\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.2213 - val_loss: 324.8697\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.4168 - val_loss: 325.1288\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 336.2057 - val_loss: 325.9171\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.4395 - val_loss: 325.3475\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.2219 - val_loss: 324.9184\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.8397 - val_loss: 324.8652\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.5500 - val_loss: 324.2365\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.1288 - val_loss: 324.1005\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.3698 - val_loss: 324.2246\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.2090 - val_loss: 324.0750\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.1335 - val_loss: 323.9822\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.0168 - val_loss: 323.0532\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.1905 - val_loss: 323.3730\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.2911 - val_loss: 323.6547\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.2499 - val_loss: 323.7404\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.9460 - val_loss: 323.2900\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.7744 - val_loss: 323.6694\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.6847 - val_loss: 323.9874\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.9551 - val_loss: 323.8569\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.0305 - val_loss: 323.7376\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.5616 - val_loss: 323.8283\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.1691 - val_loss: 323.8243\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.3996 - val_loss: 323.7610\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.2216 - val_loss: 323.4256\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.2303 - val_loss: 323.3840\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.9749 - val_loss: 323.4514\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.1079 - val_loss: 323.8391\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.1142 - val_loss: 323.3318\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.4846 - val_loss: 322.4537\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.0904 - val_loss: 322.8438\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.8615 - val_loss: 323.4058\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.9299 - val_loss: 323.1663\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.3269 - val_loss: 322.1618\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.8029 - val_loss: 321.8071\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.8655 - val_loss: 322.4556\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.9142 - val_loss: 322.7885\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.4105 - val_loss: 323.6258\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.8128 - val_loss: 323.0951\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 331.6164 - val_loss: 323.8655\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.9861 - val_loss: 323.8435\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.6265 - val_loss: 323.5693\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.7091 - val_loss: 323.1947\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.2332 - val_loss: 322.4052\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 326.4602 - val_loss: 321.8326\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 325.5953 - val_loss: 321.7250\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 326.6911 - val_loss: 321.0109\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 326.5601 - val_loss: 321.2722\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.1672 - val_loss: 320.6875\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.1295 - val_loss: 320.6313\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 326.3040 - val_loss: 320.2500\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 326.5912 - val_loss: 319.5403\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.7267 - val_loss: 320.0493\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.7914 - val_loss: 321.3093\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 332.9001 - val_loss: 322.0847\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 330.1602 - val_loss: 321.8378\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.3773 - val_loss: 322.0672\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 326.9765 - val_loss: 321.7360\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 328.4796 - val_loss: 321.2177\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 325.8475 - val_loss: 321.0146\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 329.4346 - val_loss: 321.1498\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 325.8453 - val_loss: 320.8858\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 327.8487 - val_loss: 320.8553\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 325.1238 - val_loss: 319.0500\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 333.2941 - val_loss: 319.5759\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "hist = model.fit(X_train, y_train, epochs=200, batch_size=32,validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습과정 확인\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  313.8495788574219\n",
      "Validataion Score:  319.575927734375\n",
      "Test Score:  315.566162109375\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: ', trainScore)\n",
    "valScore = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Validataion Score: ', valScore)\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: ', testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
